{
  "best_global_step": 2504,
  "best_metric": 8.341828346252441,
  "best_model_checkpoint": "/home/arnau-marcos-almansa/workspace/C5_Project/Week1/RT-DETER/Results_RTDETR/finetune/checkpoint-2504",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 4382,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07987220447284345,
      "grad_norm": 359.3271789550781,
      "learning_rate": 7.82747603833866e-06,
      "loss": 208.07326171875,
      "step": 50
    },
    {
      "epoch": 0.1597444089456869,
      "grad_norm": 342.9757080078125,
      "learning_rate": 1.5814696485623005e-05,
      "loss": 195.0333203125,
      "step": 100
    },
    {
      "epoch": 0.23961661341853036,
      "grad_norm": 212.49598693847656,
      "learning_rate": 2.380191693290735e-05,
      "loss": 179.26357421875,
      "step": 150
    },
    {
      "epoch": 0.3194888178913738,
      "grad_norm": 161.72869873046875,
      "learning_rate": 3.17891373801917e-05,
      "loss": 139.67041015625,
      "step": 200
    },
    {
      "epoch": 0.3993610223642173,
      "grad_norm": 259.923095703125,
      "learning_rate": 3.9776357827476044e-05,
      "loss": 105.040908203125,
      "step": 250
    },
    {
      "epoch": 0.4792332268370607,
      "grad_norm": 81.91680145263672,
      "learning_rate": 4.776357827476038e-05,
      "loss": 61.471201171875,
      "step": 300
    },
    {
      "epoch": 0.5591054313099042,
      "grad_norm": 73.50827026367188,
      "learning_rate": 5.575079872204473e-05,
      "loss": 40.9288037109375,
      "step": 350
    },
    {
      "epoch": 0.6389776357827476,
      "grad_norm": 31.46774673461914,
      "learning_rate": 6.373801916932908e-05,
      "loss": 31.6282373046875,
      "step": 400
    },
    {
      "epoch": 0.7188498402555911,
      "grad_norm": 29.362089157104492,
      "learning_rate": 7.172523961661343e-05,
      "loss": 25.94282958984375,
      "step": 450
    },
    {
      "epoch": 0.7987220447284346,
      "grad_norm": 49.2603645324707,
      "learning_rate": 7.971246006389777e-05,
      "loss": 21.6166357421875,
      "step": 500
    },
    {
      "epoch": 0.8785942492012779,
      "grad_norm": 30.635835647583008,
      "learning_rate": 8.769968051118212e-05,
      "loss": 18.61439208984375,
      "step": 550
    },
    {
      "epoch": 0.9584664536741214,
      "grad_norm": 14.074209213256836,
      "learning_rate": 9.568690095846646e-05,
      "loss": 16.47104736328125,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 14.482967376708984,
      "eval_runtime": 38.8114,
      "eval_samples_per_second": 75.236,
      "eval_steps_per_second": 9.404,
      "step": 626
    },
    {
      "epoch": 1.038338658146965,
      "grad_norm": 12.430994033813477,
      "learning_rate": 9.999588797460659e-05,
      "loss": 16.274151611328126,
      "step": 650
    },
    {
      "epoch": 1.1182108626198084,
      "grad_norm": 8.853026390075684,
      "learning_rate": 9.995858174278537e-05,
      "loss": 14.643836669921875,
      "step": 700
    },
    {
      "epoch": 1.1980830670926517,
      "grad_norm": 15.528299331665039,
      "learning_rate": 9.98824436649457e-05,
      "loss": 14.669468994140624,
      "step": 750
    },
    {
      "epoch": 1.2779552715654952,
      "grad_norm": 21.325475692749023,
      "learning_rate": 9.976753292175314e-05,
      "loss": 14.141300048828125,
      "step": 800
    },
    {
      "epoch": 1.3578274760383386,
      "grad_norm": 22.629642486572266,
      "learning_rate": 9.961393883112119e-05,
      "loss": 13.741138916015625,
      "step": 850
    },
    {
      "epoch": 1.4376996805111821,
      "grad_norm": 25.074771881103516,
      "learning_rate": 9.942178077878639e-05,
      "loss": 13.77988525390625,
      "step": 900
    },
    {
      "epoch": 1.5175718849840254,
      "grad_norm": 22.329811096191406,
      "learning_rate": 9.919120812551198e-05,
      "loss": 13.759095458984374,
      "step": 950
    },
    {
      "epoch": 1.5974440894568689,
      "grad_norm": 24.93244743347168,
      "learning_rate": 9.892240009099266e-05,
      "loss": 13.554130859375,
      "step": 1000
    },
    {
      "epoch": 1.6773162939297124,
      "grad_norm": 28.54640769958496,
      "learning_rate": 9.86155656145506e-05,
      "loss": 13.602962646484375,
      "step": 1050
    },
    {
      "epoch": 1.7571884984025559,
      "grad_norm": 28.956090927124023,
      "learning_rate": 9.827094319273085e-05,
      "loss": 13.15975341796875,
      "step": 1100
    },
    {
      "epoch": 1.8370607028753994,
      "grad_norm": 37.186248779296875,
      "learning_rate": 9.788880069392263e-05,
      "loss": 13.300716552734375,
      "step": 1150
    },
    {
      "epoch": 1.9169329073482428,
      "grad_norm": 13.093677520751953,
      "learning_rate": 9.746943515015033e-05,
      "loss": 12.7222119140625,
      "step": 1200
    },
    {
      "epoch": 1.9968051118210863,
      "grad_norm": 24.639039993286133,
      "learning_rate": 9.701317252619624e-05,
      "loss": 12.78410888671875,
      "step": 1250
    },
    {
      "epoch": 2.0,
      "eval_loss": 8.828459739685059,
      "eval_runtime": 38.9333,
      "eval_samples_per_second": 75.0,
      "eval_steps_per_second": 9.375,
      "step": 1252
    },
    {
      "epoch": 2.07667731629393,
      "grad_norm": 17.805255889892578,
      "learning_rate": 9.652036746623438e-05,
      "loss": 13.001385498046876,
      "step": 1300
    },
    {
      "epoch": 2.1565495207667733,
      "grad_norm": 25.155742645263672,
      "learning_rate": 9.599140301817239e-05,
      "loss": 12.691949462890625,
      "step": 1350
    },
    {
      "epoch": 2.236421725239617,
      "grad_norm": 15.71638011932373,
      "learning_rate": 9.542669033591576e-05,
      "loss": 12.610025634765625,
      "step": 1400
    },
    {
      "epoch": 2.31629392971246,
      "grad_norm": 10.898507118225098,
      "learning_rate": 9.48266683597858e-05,
      "loss": 12.76493408203125,
      "step": 1450
    },
    {
      "epoch": 2.3961661341853033,
      "grad_norm": 16.279680252075195,
      "learning_rate": 9.419180347533976e-05,
      "loss": 12.4571533203125,
      "step": 1500
    },
    {
      "epoch": 2.476038338658147,
      "grad_norm": 20.45458221435547,
      "learning_rate": 9.352258915085823e-05,
      "loss": 12.96759765625,
      "step": 1550
    },
    {
      "epoch": 2.5559105431309903,
      "grad_norm": 18.317602157592773,
      "learning_rate": 9.281954555378184e-05,
      "loss": 12.52758544921875,
      "step": 1600
    },
    {
      "epoch": 2.635782747603834,
      "grad_norm": 17.834810256958008,
      "learning_rate": 9.208321914639503e-05,
      "loss": 12.432264404296875,
      "step": 1650
    },
    {
      "epoch": 2.7156549520766773,
      "grad_norm": 16.034101486206055,
      "learning_rate": 9.13141822610714e-05,
      "loss": 12.595,
      "step": 1700
    },
    {
      "epoch": 2.7955271565495208,
      "grad_norm": 21.288789749145508,
      "learning_rate": 9.051303265541078e-05,
      "loss": 12.42971923828125,
      "step": 1750
    },
    {
      "epoch": 2.8753993610223643,
      "grad_norm": 10.434516906738281,
      "learning_rate": 8.968039304761368e-05,
      "loss": 12.658734130859376,
      "step": 1800
    },
    {
      "epoch": 2.9552715654952078,
      "grad_norm": 13.156594276428223,
      "learning_rate": 8.881691063245453e-05,
      "loss": 12.200994873046875,
      "step": 1850
    },
    {
      "epoch": 3.0,
      "eval_loss": 8.442195892333984,
      "eval_runtime": 38.9242,
      "eval_samples_per_second": 75.018,
      "eval_steps_per_second": 9.377,
      "step": 1878
    },
    {
      "epoch": 3.0351437699680512,
      "grad_norm": 28.202106475830078,
      "learning_rate": 8.792325657822941e-05,
      "loss": 12.444498291015625,
      "step": 1900
    },
    {
      "epoch": 3.1150159744408947,
      "grad_norm": 11.124530792236328,
      "learning_rate": 8.700012550507e-05,
      "loss": 12.43097412109375,
      "step": 1950
    },
    {
      "epoch": 3.194888178913738,
      "grad_norm": 24.706615447998047,
      "learning_rate": 8.604823494502859e-05,
      "loss": 12.31554443359375,
      "step": 2000
    },
    {
      "epoch": 3.2747603833865817,
      "grad_norm": 38.404075622558594,
      "learning_rate": 8.506832478435422e-05,
      "loss": 12.214522705078124,
      "step": 2050
    },
    {
      "epoch": 3.3546325878594248,
      "grad_norm": 26.977231979370117,
      "learning_rate": 8.406115668839333e-05,
      "loss": 12.390645751953125,
      "step": 2100
    },
    {
      "epoch": 3.4345047923322682,
      "grad_norm": 11.16996955871582,
      "learning_rate": 8.302751350956197e-05,
      "loss": 12.4205517578125,
      "step": 2150
    },
    {
      "epoch": 3.5143769968051117,
      "grad_norm": 15.70431137084961,
      "learning_rate": 8.19681986788495e-05,
      "loss": 12.28489013671875,
      "step": 2200
    },
    {
      "epoch": 3.594249201277955,
      "grad_norm": 11.342726707458496,
      "learning_rate": 8.088403558132723e-05,
      "loss": 12.178095703125,
      "step": 2250
    },
    {
      "epoch": 3.6741214057507987,
      "grad_norm": 15.428028106689453,
      "learning_rate": 7.9775866916147e-05,
      "loss": 12.17375244140625,
      "step": 2300
    },
    {
      "epoch": 3.753993610223642,
      "grad_norm": 28.915687561035156,
      "learning_rate": 7.864455404152734e-05,
      "loss": 12.295255126953125,
      "step": 2350
    },
    {
      "epoch": 3.8338658146964857,
      "grad_norm": 9.25019359588623,
      "learning_rate": 7.749097630523619e-05,
      "loss": 12.169647216796875,
      "step": 2400
    },
    {
      "epoch": 3.913738019169329,
      "grad_norm": 22.84156608581543,
      "learning_rate": 7.631603036109082e-05,
      "loss": 11.8889697265625,
      "step": 2450
    },
    {
      "epoch": 3.9936102236421727,
      "grad_norm": 15.34760856628418,
      "learning_rate": 7.51206294720061e-05,
      "loss": 12.3891259765625,
      "step": 2500
    },
    {
      "epoch": 4.0,
      "eval_loss": 8.341828346252441,
      "eval_runtime": 39.1283,
      "eval_samples_per_second": 74.626,
      "eval_steps_per_second": 9.328,
      "step": 2504
    },
    {
      "epoch": 4.073482428115016,
      "grad_norm": 25.364408493041992,
      "learning_rate": 7.39057028001326e-05,
      "loss": 12.093651123046875,
      "step": 2550
    },
    {
      "epoch": 4.15335463258786,
      "grad_norm": 31.56983184814453,
      "learning_rate": 7.267219468463698e-05,
      "loss": 11.78097900390625,
      "step": 2600
    },
    {
      "epoch": 4.233226837060703,
      "grad_norm": 36.66197204589844,
      "learning_rate": 7.142106390768495e-05,
      "loss": 11.99203125,
      "step": 2650
    },
    {
      "epoch": 4.313099041533547,
      "grad_norm": 16.70199966430664,
      "learning_rate": 7.015328294919863e-05,
      "loss": 11.915220947265626,
      "step": 2700
    },
    {
      "epoch": 4.39297124600639,
      "grad_norm": 22.317646026611328,
      "learning_rate": 6.886983723096637e-05,
      "loss": 12.058875732421875,
      "step": 2750
    },
    {
      "epoch": 4.472843450479234,
      "grad_norm": 17.24651527404785,
      "learning_rate": 6.757172435069339e-05,
      "loss": 12.041983642578124,
      "step": 2800
    },
    {
      "epoch": 4.552715654952077,
      "grad_norm": 23.779956817626953,
      "learning_rate": 6.625995330658827e-05,
      "loss": 12.065830078125,
      "step": 2850
    },
    {
      "epoch": 4.63258785942492,
      "grad_norm": 11.388708114624023,
      "learning_rate": 6.4935543713088e-05,
      "loss": 12.208206787109376,
      "step": 2900
    },
    {
      "epoch": 4.712460063897764,
      "grad_norm": 13.47878646850586,
      "learning_rate": 6.359952500833124e-05,
      "loss": 12.1344873046875,
      "step": 2950
    },
    {
      "epoch": 4.792332268370607,
      "grad_norm": 14.561821937561035,
      "learning_rate": 6.225293565399588e-05,
      "loss": 11.767039794921875,
      "step": 3000
    },
    {
      "epoch": 4.872204472843451,
      "grad_norm": 11.059959411621094,
      "learning_rate": 6.089682232812266e-05,
      "loss": 12.00325927734375,
      "step": 3050
    },
    {
      "epoch": 4.952076677316294,
      "grad_norm": 10.257002830505371,
      "learning_rate": 5.9532239111552503e-05,
      "loss": 12.194442138671874,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_loss": 8.484807968139648,
      "eval_runtime": 39.023,
      "eval_samples_per_second": 74.828,
      "eval_steps_per_second": 9.353,
      "step": 3130
    },
    {
      "epoch": 5.031948881789138,
      "grad_norm": 14.736244201660156,
      "learning_rate": 5.816024666860966e-05,
      "loss": 12.4258837890625,
      "step": 3150
    },
    {
      "epoch": 5.111821086261981,
      "grad_norm": 16.677061080932617,
      "learning_rate": 5.6781911422667736e-05,
      "loss": 11.942003173828125,
      "step": 3200
    },
    {
      "epoch": 5.1916932907348246,
      "grad_norm": 15.877147674560547,
      "learning_rate": 5.539830472723929e-05,
      "loss": 12.057991943359376,
      "step": 3250
    },
    {
      "epoch": 5.271565495207668,
      "grad_norm": 23.80428695678711,
      "learning_rate": 5.40105020332333e-05,
      "loss": 11.735885009765624,
      "step": 3300
    },
    {
      "epoch": 5.3514376996805115,
      "grad_norm": 14.126076698303223,
      "learning_rate": 5.261958205302786e-05,
      "loss": 11.703648681640624,
      "step": 3350
    },
    {
      "epoch": 5.431309904153355,
      "grad_norm": 9.064687728881836,
      "learning_rate": 5.122662592200774e-05,
      "loss": 11.750426025390626,
      "step": 3400
    },
    {
      "epoch": 5.511182108626198,
      "grad_norm": 15.024707794189453,
      "learning_rate": 4.9832716358218614e-05,
      "loss": 11.801422119140625,
      "step": 3450
    },
    {
      "epoch": 5.5910543130990416,
      "grad_norm": 10.836687088012695,
      "learning_rate": 4.843893682079121e-05,
      "loss": 11.947640380859376,
      "step": 3500
    },
    {
      "epoch": 5.6709265175718855,
      "grad_norm": 14.390993118286133,
      "learning_rate": 4.7046370667789136e-05,
      "loss": 12.12101318359375,
      "step": 3550
    },
    {
      "epoch": 5.7507987220447285,
      "grad_norm": 17.252605438232422,
      "learning_rate": 4.565610031413573e-05,
      "loss": 11.86444580078125,
      "step": 3600
    },
    {
      "epoch": 5.830670926517572,
      "grad_norm": 34.8319206237793,
      "learning_rate": 4.4269206390273476e-05,
      "loss": 11.9857080078125,
      "step": 3650
    },
    {
      "epoch": 5.9105431309904155,
      "grad_norm": 8.688159942626953,
      "learning_rate": 4.2886766902210914e-05,
      "loss": 11.954642333984374,
      "step": 3700
    },
    {
      "epoch": 5.9904153354632586,
      "grad_norm": 18.2539119720459,
      "learning_rate": 4.1509856393609136e-05,
      "loss": 11.86667236328125,
      "step": 3750
    },
    {
      "epoch": 6.0,
      "eval_loss": 8.417936325073242,
      "eval_runtime": 38.9244,
      "eval_samples_per_second": 75.017,
      "eval_steps_per_second": 9.377,
      "step": 3756
    },
    {
      "epoch": 6.0702875399361025,
      "grad_norm": 13.688104629516602,
      "learning_rate": 4.013954511055975e-05,
      "loss": 11.781697998046875,
      "step": 3800
    },
    {
      "epoch": 6.1501597444089455,
      "grad_norm": 14.053668022155762,
      "learning_rate": 3.8776898169703043e-05,
      "loss": 11.537083740234374,
      "step": 3850
    },
    {
      "epoch": 6.2300319488817895,
      "grad_norm": 12.162221908569336,
      "learning_rate": 3.742297473033339e-05,
      "loss": 11.717674560546875,
      "step": 3900
    },
    {
      "epoch": 6.3099041533546325,
      "grad_norm": 6.65346622467041,
      "learning_rate": 3.6078827171134935e-05,
      "loss": 11.90603515625,
      "step": 3950
    },
    {
      "epoch": 6.389776357827476,
      "grad_norm": 14.607934951782227,
      "learning_rate": 3.474550027218803e-05,
      "loss": 12.1999462890625,
      "step": 4000
    },
    {
      "epoch": 6.4696485623003195,
      "grad_norm": 17.97460174560547,
      "learning_rate": 3.342403040288151e-05,
      "loss": 11.95595947265625,
      "step": 4050
    },
    {
      "epoch": 6.549520766773163,
      "grad_norm": 16.099018096923828,
      "learning_rate": 3.2115444716363e-05,
      "loss": 11.806204833984374,
      "step": 4100
    },
    {
      "epoch": 6.6293929712460065,
      "grad_norm": 19.17578887939453,
      "learning_rate": 3.082076035115214e-05,
      "loss": 11.6045361328125,
      "step": 4150
    },
    {
      "epoch": 6.7092651757188495,
      "grad_norm": 14.334870338439941,
      "learning_rate": 2.9540983640538635e-05,
      "loss": 11.97226318359375,
      "step": 4200
    },
    {
      "epoch": 6.789137380191693,
      "grad_norm": 14.182156562805176,
      "learning_rate": 2.8277109330378525e-05,
      "loss": 11.870316162109376,
      "step": 4250
    },
    {
      "epoch": 6.8690095846645365,
      "grad_norm": 17.126008987426758,
      "learning_rate": 2.7030119805897547e-05,
      "loss": 11.83243896484375,
      "step": 4300
    },
    {
      "epoch": 6.94888178913738,
      "grad_norm": 26.743457794189453,
      "learning_rate": 2.5800984328101663e-05,
      "loss": 11.802879638671875,
      "step": 4350
    },
    {
      "epoch": 7.0,
      "eval_loss": 8.366369247436523,
      "eval_runtime": 38.8146,
      "eval_samples_per_second": 75.229,
      "eval_steps_per_second": 9.404,
      "step": 4382
    }
  ],
  "logging_steps": 50,
  "max_steps": 6260,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.005
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9788860229820416e+19,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
