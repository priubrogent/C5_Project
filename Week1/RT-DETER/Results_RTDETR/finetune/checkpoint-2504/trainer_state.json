{
  "best_global_step": 2504,
  "best_metric": 8.341828346252441,
  "best_model_checkpoint": "/home/arnau-marcos-almansa/workspace/C5_Project/Week1/RT-DETER/Results_RTDETR/finetune/checkpoint-2504",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 2504,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07987220447284345,
      "grad_norm": 359.3271789550781,
      "learning_rate": 7.82747603833866e-06,
      "loss": 208.07326171875,
      "step": 50
    },
    {
      "epoch": 0.1597444089456869,
      "grad_norm": 342.9757080078125,
      "learning_rate": 1.5814696485623005e-05,
      "loss": 195.0333203125,
      "step": 100
    },
    {
      "epoch": 0.23961661341853036,
      "grad_norm": 212.49598693847656,
      "learning_rate": 2.380191693290735e-05,
      "loss": 179.26357421875,
      "step": 150
    },
    {
      "epoch": 0.3194888178913738,
      "grad_norm": 161.72869873046875,
      "learning_rate": 3.17891373801917e-05,
      "loss": 139.67041015625,
      "step": 200
    },
    {
      "epoch": 0.3993610223642173,
      "grad_norm": 259.923095703125,
      "learning_rate": 3.9776357827476044e-05,
      "loss": 105.040908203125,
      "step": 250
    },
    {
      "epoch": 0.4792332268370607,
      "grad_norm": 81.91680145263672,
      "learning_rate": 4.776357827476038e-05,
      "loss": 61.471201171875,
      "step": 300
    },
    {
      "epoch": 0.5591054313099042,
      "grad_norm": 73.50827026367188,
      "learning_rate": 5.575079872204473e-05,
      "loss": 40.9288037109375,
      "step": 350
    },
    {
      "epoch": 0.6389776357827476,
      "grad_norm": 31.46774673461914,
      "learning_rate": 6.373801916932908e-05,
      "loss": 31.6282373046875,
      "step": 400
    },
    {
      "epoch": 0.7188498402555911,
      "grad_norm": 29.362089157104492,
      "learning_rate": 7.172523961661343e-05,
      "loss": 25.94282958984375,
      "step": 450
    },
    {
      "epoch": 0.7987220447284346,
      "grad_norm": 49.2603645324707,
      "learning_rate": 7.971246006389777e-05,
      "loss": 21.6166357421875,
      "step": 500
    },
    {
      "epoch": 0.8785942492012779,
      "grad_norm": 30.635835647583008,
      "learning_rate": 8.769968051118212e-05,
      "loss": 18.61439208984375,
      "step": 550
    },
    {
      "epoch": 0.9584664536741214,
      "grad_norm": 14.074209213256836,
      "learning_rate": 9.568690095846646e-05,
      "loss": 16.47104736328125,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 14.482967376708984,
      "eval_runtime": 38.8114,
      "eval_samples_per_second": 75.236,
      "eval_steps_per_second": 9.404,
      "step": 626
    },
    {
      "epoch": 1.038338658146965,
      "grad_norm": 12.430994033813477,
      "learning_rate": 9.999588797460659e-05,
      "loss": 16.274151611328126,
      "step": 650
    },
    {
      "epoch": 1.1182108626198084,
      "grad_norm": 8.853026390075684,
      "learning_rate": 9.995858174278537e-05,
      "loss": 14.643836669921875,
      "step": 700
    },
    {
      "epoch": 1.1980830670926517,
      "grad_norm": 15.528299331665039,
      "learning_rate": 9.98824436649457e-05,
      "loss": 14.669468994140624,
      "step": 750
    },
    {
      "epoch": 1.2779552715654952,
      "grad_norm": 21.325475692749023,
      "learning_rate": 9.976753292175314e-05,
      "loss": 14.141300048828125,
      "step": 800
    },
    {
      "epoch": 1.3578274760383386,
      "grad_norm": 22.629642486572266,
      "learning_rate": 9.961393883112119e-05,
      "loss": 13.741138916015625,
      "step": 850
    },
    {
      "epoch": 1.4376996805111821,
      "grad_norm": 25.074771881103516,
      "learning_rate": 9.942178077878639e-05,
      "loss": 13.77988525390625,
      "step": 900
    },
    {
      "epoch": 1.5175718849840254,
      "grad_norm": 22.329811096191406,
      "learning_rate": 9.919120812551198e-05,
      "loss": 13.759095458984374,
      "step": 950
    },
    {
      "epoch": 1.5974440894568689,
      "grad_norm": 24.93244743347168,
      "learning_rate": 9.892240009099266e-05,
      "loss": 13.554130859375,
      "step": 1000
    },
    {
      "epoch": 1.6773162939297124,
      "grad_norm": 28.54640769958496,
      "learning_rate": 9.86155656145506e-05,
      "loss": 13.602962646484375,
      "step": 1050
    },
    {
      "epoch": 1.7571884984025559,
      "grad_norm": 28.956090927124023,
      "learning_rate": 9.827094319273085e-05,
      "loss": 13.15975341796875,
      "step": 1100
    },
    {
      "epoch": 1.8370607028753994,
      "grad_norm": 37.186248779296875,
      "learning_rate": 9.788880069392263e-05,
      "loss": 13.300716552734375,
      "step": 1150
    },
    {
      "epoch": 1.9169329073482428,
      "grad_norm": 13.093677520751953,
      "learning_rate": 9.746943515015033e-05,
      "loss": 12.7222119140625,
      "step": 1200
    },
    {
      "epoch": 1.9968051118210863,
      "grad_norm": 24.639039993286133,
      "learning_rate": 9.701317252619624e-05,
      "loss": 12.78410888671875,
      "step": 1250
    },
    {
      "epoch": 2.0,
      "eval_loss": 8.828459739685059,
      "eval_runtime": 38.9333,
      "eval_samples_per_second": 75.0,
      "eval_steps_per_second": 9.375,
      "step": 1252
    },
    {
      "epoch": 2.07667731629393,
      "grad_norm": 17.805255889892578,
      "learning_rate": 9.652036746623438e-05,
      "loss": 13.001385498046876,
      "step": 1300
    },
    {
      "epoch": 2.1565495207667733,
      "grad_norm": 25.155742645263672,
      "learning_rate": 9.599140301817239e-05,
      "loss": 12.691949462890625,
      "step": 1350
    },
    {
      "epoch": 2.236421725239617,
      "grad_norm": 15.71638011932373,
      "learning_rate": 9.542669033591576e-05,
      "loss": 12.610025634765625,
      "step": 1400
    },
    {
      "epoch": 2.31629392971246,
      "grad_norm": 10.898507118225098,
      "learning_rate": 9.48266683597858e-05,
      "loss": 12.76493408203125,
      "step": 1450
    },
    {
      "epoch": 2.3961661341853033,
      "grad_norm": 16.279680252075195,
      "learning_rate": 9.419180347533976e-05,
      "loss": 12.4571533203125,
      "step": 1500
    },
    {
      "epoch": 2.476038338658147,
      "grad_norm": 20.45458221435547,
      "learning_rate": 9.352258915085823e-05,
      "loss": 12.96759765625,
      "step": 1550
    },
    {
      "epoch": 2.5559105431309903,
      "grad_norm": 18.317602157592773,
      "learning_rate": 9.281954555378184e-05,
      "loss": 12.52758544921875,
      "step": 1600
    },
    {
      "epoch": 2.635782747603834,
      "grad_norm": 17.834810256958008,
      "learning_rate": 9.208321914639503e-05,
      "loss": 12.432264404296875,
      "step": 1650
    },
    {
      "epoch": 2.7156549520766773,
      "grad_norm": 16.034101486206055,
      "learning_rate": 9.13141822610714e-05,
      "loss": 12.595,
      "step": 1700
    },
    {
      "epoch": 2.7955271565495208,
      "grad_norm": 21.288789749145508,
      "learning_rate": 9.051303265541078e-05,
      "loss": 12.42971923828125,
      "step": 1750
    },
    {
      "epoch": 2.8753993610223643,
      "grad_norm": 10.434516906738281,
      "learning_rate": 8.968039304761368e-05,
      "loss": 12.658734130859376,
      "step": 1800
    },
    {
      "epoch": 2.9552715654952078,
      "grad_norm": 13.156594276428223,
      "learning_rate": 8.881691063245453e-05,
      "loss": 12.200994873046875,
      "step": 1850
    },
    {
      "epoch": 3.0,
      "eval_loss": 8.442195892333984,
      "eval_runtime": 38.9242,
      "eval_samples_per_second": 75.018,
      "eval_steps_per_second": 9.377,
      "step": 1878
    },
    {
      "epoch": 3.0351437699680512,
      "grad_norm": 28.202106475830078,
      "learning_rate": 8.792325657822941e-05,
      "loss": 12.444498291015625,
      "step": 1900
    },
    {
      "epoch": 3.1150159744408947,
      "grad_norm": 11.124530792236328,
      "learning_rate": 8.700012550507e-05,
      "loss": 12.43097412109375,
      "step": 1950
    },
    {
      "epoch": 3.194888178913738,
      "grad_norm": 24.706615447998047,
      "learning_rate": 8.604823494502859e-05,
      "loss": 12.31554443359375,
      "step": 2000
    },
    {
      "epoch": 3.2747603833865817,
      "grad_norm": 38.404075622558594,
      "learning_rate": 8.506832478435422e-05,
      "loss": 12.214522705078124,
      "step": 2050
    },
    {
      "epoch": 3.3546325878594248,
      "grad_norm": 26.977231979370117,
      "learning_rate": 8.406115668839333e-05,
      "loss": 12.390645751953125,
      "step": 2100
    },
    {
      "epoch": 3.4345047923322682,
      "grad_norm": 11.16996955871582,
      "learning_rate": 8.302751350956197e-05,
      "loss": 12.4205517578125,
      "step": 2150
    },
    {
      "epoch": 3.5143769968051117,
      "grad_norm": 15.70431137084961,
      "learning_rate": 8.19681986788495e-05,
      "loss": 12.28489013671875,
      "step": 2200
    },
    {
      "epoch": 3.594249201277955,
      "grad_norm": 11.342726707458496,
      "learning_rate": 8.088403558132723e-05,
      "loss": 12.178095703125,
      "step": 2250
    },
    {
      "epoch": 3.6741214057507987,
      "grad_norm": 15.428028106689453,
      "learning_rate": 7.9775866916147e-05,
      "loss": 12.17375244140625,
      "step": 2300
    },
    {
      "epoch": 3.753993610223642,
      "grad_norm": 28.915687561035156,
      "learning_rate": 7.864455404152734e-05,
      "loss": 12.295255126953125,
      "step": 2350
    },
    {
      "epoch": 3.8338658146964857,
      "grad_norm": 9.25019359588623,
      "learning_rate": 7.749097630523619e-05,
      "loss": 12.169647216796875,
      "step": 2400
    },
    {
      "epoch": 3.913738019169329,
      "grad_norm": 22.84156608581543,
      "learning_rate": 7.631603036109082e-05,
      "loss": 11.8889697265625,
      "step": 2450
    },
    {
      "epoch": 3.9936102236421727,
      "grad_norm": 15.34760856628418,
      "learning_rate": 7.51206294720061e-05,
      "loss": 12.3891259765625,
      "step": 2500
    },
    {
      "epoch": 4.0,
      "eval_loss": 8.341828346252441,
      "eval_runtime": 39.1283,
      "eval_samples_per_second": 74.626,
      "eval_steps_per_second": 9.328,
      "step": 2504
    }
  ],
  "logging_steps": 50,
  "max_steps": 6260,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.005
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1307920131325952e+19,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
